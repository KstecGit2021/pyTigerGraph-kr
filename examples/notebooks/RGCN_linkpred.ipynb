{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "import pyTigerGraph\n",
    "pyTigerGraph.__path__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Recommender System with EvolveGCN on PyG\n",
    "Dataset: LastFM (based: [JODIE: Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks](http://snap.stanford.edu/jodie/))\n",
    "GNN Model: LightGCN [\\[2002.02126\\] LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation](https://arxiv.org/abs/2002.02126)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Connect to TigerGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyTigerGraph import TigerGraphConnection\n",
    "\n",
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # Change the address to your database server's\n",
    "    graphname=\"LastFM_hetrec\",  # Specify LastFM (HetRec) dataset\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Basic metadata about the graph such as schema.\n",
    "# print(conn.gsql(\"ls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Vertex Count:\", conn.getVertexCount('*'))\n",
    "print(\"Edge Count:\", conn.getEdgeCount('*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(Custimization Point for pyTigerGraph)\n",
    " In order to handle bipartite graphs which is comprised of users and items, we explicty specify # of users and items - which is required to compute the similarty score between user embeddings and items embeddings in GNN models.  To create a matrix for users/items embedding, we need to know # of users and items.  To that end. pyTigerGraph should support functions or attributes to extract these numbers for bipartite graphs - by propopsing two functions - tgraph.number_of_source_vertices(), tgraph.number_of_target_vertices(). These proposed methods should be used for general graphs as long as we target recommendation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_users, num_items, num_tags = conn.getVertexCount(\"UserH\"), conn.getVertexCount(\"Artist\"), conn.getVertexCount(\"Tag\")\n",
    "num_user_items = num_users + num_items\n",
    "num_nodes = num_user_items + num_tags\n",
    "num_user_items, num_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In recommendation tasks, the input dataset must be split by edges instead of nodes. pyTigerGraph supports node masking to split dataset, but edge masking and custom functions, which extract subgraphs with specified set of edges (training / validation / testing edges ), should be also provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train : Val : Test = 70 : 15 : 15\n",
    "splitter = conn.gds.edgeSplitter(train_mask=0.70, val_mask=0.15, test_mask=0.15)\n",
    "splitter.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Graph loader with edge features\n",
    "Currently the `GraphLoader` of pyTigerGraph only considers node-based labels but for recommender systems, it needs to support edge-based labels (training/validation/testing) to split datasets into training/validation/testing datasets by edge masking and custom functions. To implement this feature, we need to write GSQL to get edge-based labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph_loader = conn.gds.graphLoader(\n",
    "    v_in_feats=[\"x\"],\n",
    "    v_out_labels=[],\n",
    "    v_extra_feats=[],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"edge_type\", \"train_mask\", \"val_mask\", \"test_mask\"],\n",
    "    num_batches=1,\n",
    "    shuffle=False,\n",
    "    output_format=\"PyG\",\n",
    "    add_self_loop=False,\n",
    "    loader_id=None,\n",
    "    buffer_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the whole graph from the loader in PyG format\n",
    "whole_graph = graph_loader.data\n",
    "print(whole_graph.edge_type)\n",
    "whole_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extract sub-dataset by edges\n",
    "The following codes are not needed for node classification since PyG supports node-based partioning to trainining/validation/testing. As previously described, edge partioning is needed for link prediction or recommender tasks. To solve this constraint, The `GraphLoader` should provide custom functions to extract subgraphs for training/validation/testing  based on edges.  The following \"train_data\" or \"val_data'. .. indicate subgraphs in PyG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = conn.gds.graphLoader(\n",
    "    v_in_feats=[\"x\"],\n",
    "    v_out_labels=[],\n",
    "    v_extra_feats=[],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"edge_type\", \"train_mask\"],\n",
    "    num_batches=1,\n",
    "    shuffle=False,\n",
    "    filter_by=\"train_mask\",\n",
    "    output_format=\"PyG\",\n",
    "    add_self_loop=False,\n",
    "    loader_id=None,\n",
    "    buffer_size=4\n",
    ")\n",
    "train_graph = train_loader.data\n",
    "\n",
    "val_loader = conn.gds.graphLoader(\n",
    "    v_in_feats=[\"x\"],\n",
    "    v_out_labels=[],\n",
    "    v_extra_feats=[],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"edge_type\", \"val_mask\"],\n",
    "    num_batches=1,\n",
    "    shuffle=False,\n",
    "    filter_by=\"val_mask\",\n",
    "    output_format=\"PyG\",\n",
    "    add_self_loop=False,\n",
    "    loader_id=None,\n",
    "    buffer_size=4\n",
    ")\n",
    "val_graph = val_loader.data\n",
    "\n",
    "test_loader = conn.gds.graphLoader(\n",
    "    v_in_feats=[\"x\"],\n",
    "    v_out_labels=[],\n",
    "    v_extra_feats=[],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"edge_type\", \"test_mask\"],\n",
    "    num_batches=1,\n",
    "    shuffle=False,\n",
    "    filter_by=\"test_mask\",\n",
    "    output_format=\"PyG\",\n",
    "    add_self_loop=False,\n",
    "    loader_id=None,\n",
    "    buffer_size=4\n",
    ")\n",
    "test_graph = test_loader.data\n",
    "\n",
    "print(\"train_graph:\", train_graph)\n",
    "print(\"val_graph:\", val_graph)\n",
    "print(\"test_graph:\", test_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and set bipartite edges to train/val/test subgraphs\n",
    "\n",
    "For each subgraph dataset (training, validation and testing), construct undirected bipartite edges for message passing in the LightGCN model from the directed edges as the ground-truth labels of the link prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "train_edge_index_d = train_graph.edge_index\n",
    "train_edge_type = train_graph.edge_type\n",
    "train_edge_index_u, train_edge_type_u = to_undirected(train_edge_index_d, edge_attr=train_edge_type)\n",
    "train_graph.edge_label_index = train_edge_index_d\n",
    "train_graph.edge_index = train_edge_index_u\n",
    "train_graph.edge_type = train_edge_type_u\n",
    "\n",
    "val_edge_index_d = val_graph.edge_index\n",
    "val_edge_type = val_graph.edge_type\n",
    "val_edge_index_u, val_edge_type_u = to_undirected(val_edge_index_d, edge_attr=val_edge_type)\n",
    "val_graph.edge_label_index = val_edge_index_d\n",
    "val_graph.edge_index = val_edge_index_u\n",
    "val_graph.edge_type = val_edge_type_u\n",
    "\n",
    "test_edge_index_d = test_graph.edge_index\n",
    "test_edge_type = test_graph.edge_type\n",
    "test_edge_index_u, test_edge_type_u = to_undirected(test_edge_index_d, edge_attr=test_edge_type)\n",
    "test_graph.edge_label_index = test_edge_index_d\n",
    "test_graph.edge_index = test_edge_index_u\n",
    "test_graph.edge_type = test_edge_type_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph, val_graph, test_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph.edge_type\n",
    "num_relations = whole_graph.edge_type.max().item() + 1  # Number of edge types\n",
    "num_relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Construct EvolveGCN model and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We build a EvolveGCN model, and use the Adam optimizer with a learning rate of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from recsys.model.rgcn import RGCN\n",
    "from recsys.config import config\n",
    "from recsys.utils.sample_negative import sample_negative_edges\n",
    "from recsys.data.lastfm import LastFMDataset, LastFMHetRecDataset\n",
    "\n",
    "print(\"EvolveGCN training configuration:\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Construct model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_dim = config.embedding_dim\n",
    "\n",
    "gnn = RGCN(\n",
    "    embedding_dim=input_dim,\n",
    "    num_nodes=num_nodes,\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    num_layers=config.num_layers,\n",
    "    num_relations=num_relations,\n",
    ").to(device)\n",
    "\n",
    "opt = torch.optim.Adam(gnn.parameters(), lr=config.lr)  # using Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "def train(\n",
    "    model,  # GNN (EvolveGCN) model\n",
    "    data_mp: Data,  # Message passing edges for multi-scale embedding propagation\n",
    "    loader: DataLoader,  # DataLoader in batches of supervision/evaluation edges\n",
    "    opt: Optimizer,  # Optimizer\n",
    "    num_users: int,  # Number of user nodes\n",
    "    num_nodes: int,  # Number of total nodes (users + items)\n",
    "    device: torch.device,  # Device (CPU or GPU)\n",
    "):\n",
    "    total_loss = 0\n",
    "    total_examples = 0\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for batch in loader:  # positive (existing) edges\n",
    "        i += 1\n",
    "        del batch.batch\n",
    "        del batch.ptr  # delete unwanted attributes\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # Generate negative (non-existing) edges\n",
    "        negs = sample_negative_edges(batch, num_users, num_user_items, device)\n",
    "        data_mp, batch, negs = data_mp.to(device), batch.to(device), negs.to(device)\n",
    "        loss = model.calc_loss(data_mp, batch, negs)  # Train and compute loss\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        num_examples = batch.edge_index.shape[1]\n",
    "        total_loss += loss.item() * num_examples\n",
    "        total_examples += num_examples\n",
    "    avg_loss = total_loss / total_examples\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def test(\n",
    "    model,  # GNN (EvolveGCN) model\n",
    "    data_mp: Data,  # Message passing edges for multi-scale embedding propagation\n",
    "    loader: DataLoader,  # DataLoader in batches of evaluation edges\n",
    "    k: int,  # Top-k\n",
    "    device: torch.device,  # Device (CPU or GPU)\n",
    "):\n",
    "    model.eval()\n",
    "    all_recalls = {}\n",
    "    with torch.no_grad():\n",
    "        data_mp = data_mp.to(device)  # Save multi-scale embeddings if save_dir is not None\n",
    "\n",
    "        # Run evaluation\n",
    "        for batch in loader:  # Batches of positive (existing) edges\n",
    "            del batch.batch; del batch.ptr  # delete unwanted attributes\n",
    "            batch = batch.to(device)\n",
    "            recalls = model.evaluation(data_mp, batch, k)  # Evaluate model performance\n",
    "            for customer_idx in recalls:\n",
    "                assert customer_idx not in all_recalls\n",
    "            all_recalls.update(recalls)\n",
    "    recall_at_k = np.mean(list(all_recalls.values()))\n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare existing edges for ground-truth data by representing them as edge list\n",
    "For each subgraph dataset (training, validation and testing), construct a `DataLoader` to load ground-truth positive (existing) edges for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "train_existing_edges = LastFMHetRecDataset(\"tmp\", edge_index=train_graph.edge_label_index, edge_type=train_graph.edge_type)\n",
    "val_existing_edges = LastFMHetRecDataset(\"tmp\", edge_index=val_graph.edge_label_index, edge_type=val_graph.edge_type)\n",
    "test_existing_edges = LastFMHetRecDataset(\"tmp\", edge_index=test_graph.edge_label_index, edge_type=test_graph.edge_type)\n",
    "\n",
    "train_label_loader = DataLoader(train_existing_edges, batch_size=config.batch_size, shuffle=True)\n",
    "val_label_loader = DataLoader(val_existing_edges, batch_size=config.batch_size, shuffle=False)\n",
    "test_label_loader = DataLoader(test_existing_edges, batch_size=config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%autoreload\n",
    "\n",
    "from time import time\n",
    "\n",
    "input_dim = config.embedding_dim\n",
    "\n",
    "all_train_losses = list()  # list of (epoch, training loss)\n",
    "all_val_recalls = list()  # list of (epoch, validation recall@k)\n",
    "all_train_recalls_lgcn = list()  # list of training recalls in LightGCN\n",
    "\n",
    "st = time()\n",
    "for epoch in range(config.epochs):\n",
    "    train_loss = train(gnn, train_graph, train_label_loader, opt, num_users, num_nodes, device)\n",
    "    all_train_losses.append((epoch, train_loss))\n",
    "\n",
    "    val_recall = test(gnn, val_graph, val_label_loader, config.k, device)\n",
    "    all_val_recalls.append((epoch, val_recall))\n",
    "    all_train_recalls_lgcn.append(val_recall)\n",
    "    tm = time() - st\n",
    "    print(f\"Epoch {epoch}: train loss={train_loss:.6f}, val_recall={val_recall:.6f}, time={tm:.2f}[s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print best validation recall@k value\n",
    "best_val_recall = max(all_val_recalls, key=lambda x: x[1])\n",
    "print(f\"Best validation recall@k: {best_val_recall[1]} at epoch {best_val_recall[0]}\")\n",
    "\n",
    "# Print final recall@k on test set\n",
    "test_recall = test(gnn, test_graph, test_label_loader, config.k, device)\n",
    "print(f\"Test set recall@k: {test_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualize testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_epochs = list(range(len(all_train_recalls_lgcn)))\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "\n",
    "plt.plot(all_epochs, all_train_recalls_lgcn, label=\"RGCN\")\n",
    "plt.ylim(bottom=0.0)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Recall@k\")\n",
    "plt.title(f\"Train recalls (top-k: {config.k}, dim: {input_dim}, lr: {config.lr})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m81"
  },
  "interpreter": {
   "hash": "a3ffc3e0035b978270c84a2ad5dd87181b12d215691cb9f2ca8be8bb187aa590"
  },
  "kernelspec": {
   "display_name": "Tigergraph Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
